LLM_PROVIDER = "Ollama"

# OpenAI
OPENAI_API_KEY = "Set your OpenAI API key here."
OPENAI_MODEL = "gpt-3.5-turbo-0125"

# Cohere
COHERE_API_KEY = "Set your Cohere API key here."
COHERE_MODEL = "command-r-plus"

# Ollama
OLLAMA_URL = "http://localhost:11434"
# The model must be available in the Ollama installation
OLLAMA_MODEL = "llama3"

LLAMAFILE_URL = "http://localhost:8080"

LLM_TEMPERATURE = "0.4"

# Solara
SOLARA_TELEMETRY_MIXPANEL_ENABLE = "False"
# This should be set to false if you have problem with write access to disk such as on Hugging Face Spaces. Otherwise, leave it as commented out, which will default to True
SOLARA_ASSETS_PROXY = "False"
